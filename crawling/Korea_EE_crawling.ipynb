{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import openpyxl\n",
    "import xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AutoFitColumnSize(worksheet, columns=None, margin=2):\n",
    "    for i, column_cells in enumerate(worksheet.columns):\n",
    "        is_ok = False\n",
    "        if columns == None:\n",
    "            is_ok = True\n",
    "        elif isinstance(columns, list) and i in columns:\n",
    "            is_ok = True\n",
    "\n",
    "        if is_ok:\n",
    "            length = max(len(str(cell.value)) for cell in column_cells)\n",
    "            worksheet.column_dimensions[column_cells[0].column_letter].width = length + margin\n",
    "\n",
    "    return worksheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = 5\n",
    "page = page * 10 + 1\n",
    "title = \"Korea_EE.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = []\n",
    "date_list = []\n",
    "url_list = []\n",
    "\n",
    "for num in range(0,page,10):\n",
    "    url = \"http://eng.korea.ac.kr/eng/community/notice.do?mode=list&&articleLimit=10&article.offset=\" + str(num)\n",
    "    html = urllib.request.urlopen(url).read()\n",
    "    text = BeautifulSoup(html,\"html.parser\")\n",
    "    table = text.find(\"div\", class_ = \"t_list test20200330\")\n",
    "    tr = table.find_all(\"tr\")\n",
    "    for (i,j) in enumerate(tr):\n",
    "        if i > 2:\n",
    "            td = tr[i].find_all('td')\n",
    "            name = td[1].find(\"a\").text\n",
    "            date = td[4].text\n",
    "            url = \"http://eng.korea.ac.kr/eng/community/notice.do\" + td[1].find(\"a\")['href']\n",
    "            name_list.append(name)\n",
    "            date_list.append(date)\n",
    "            url_list.append(url)\n",
    "data = {\"날짜\" : date_list, \"공과대학 공지사항\" : name_list,  \"url\" : url_list}\n",
    "df5 = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = []\n",
    "date_list = []\n",
    "url_list = []\n",
    "\n",
    "for num in range(0,page,10):\n",
    "    url = \"http://eng.korea.ac.kr/eng/community/questions.do?mode=list&&articleLimit=10&article.offset=\" + str(num)\n",
    "    html = urllib.request.urlopen(url).read()\n",
    "    text = BeautifulSoup(html,\"html.parser\")\n",
    "    table = text.find(\"div\", class_ = \"t_list test20200330\")\n",
    "    tr = table.find_all(\"tr\")\n",
    "    for (i,j) in enumerate(tr):\n",
    "        if i > 0:\n",
    "            td = tr[i].find_all('td')\n",
    "            name = td[1].find(\"a\").text\n",
    "            date = td[4].text\n",
    "            url = \"http://eng.korea.ac.kr/eng/community/questions.do\" + td[1].find(\"a\")['href']\n",
    "            name_list.append(name)\n",
    "            date_list.append(date)\n",
    "            url_list.append(url)\n",
    "data = {\"날짜\" : date_list, \"공과대학 취업공지\" : name_list,  \"url\" : url_list}\n",
    "df6 = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name_list = []\n",
    "date_list = []\n",
    "url_list = []\n",
    "\n",
    "for num in range(0,page,10):\n",
    "    url = \"http://ee.korea.ac.kr/ee/board/UnderNotice.do?mode=list&&articleLimit=10&article.offset=\" + str(num)\n",
    "    html = urllib.request.urlopen(url).read()\n",
    "    text = BeautifulSoup(html,\"html.parser\")\n",
    "    table = text.find(\"div\", class_ = \"t_list test20200330\")\n",
    "    tr = table.find_all(\"tr\")\n",
    "    for (i,j) in enumerate(tr):\n",
    "        if i > 2:\n",
    "            td = tr[i].find_all('td')\n",
    "            name = td[1].find(\"a\").text\n",
    "            date = td[4].text\n",
    "            url = \"http://ee.korea.ac.kr/ee/board/UnderNotice.do\" + td[1].find(\"a\")['href']\n",
    "            name_list.append(name)\n",
    "            date_list.append(date)\n",
    "            url_list.append(url)\n",
    "data = {\"날짜\" : date_list, \"전전 공지사항\" : name_list,  \"url\" : url_list}\n",
    "df1 = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name_list = []\n",
    "date_list = []\n",
    "url_list = []\n",
    "\n",
    "for num in range(0,page,10):\n",
    "    url = \"http://ee.korea.ac.kr/ee/board/MajorBulletinBoard.do?mode=list&&articleLimit=10&article.offset=\" + str(num)\n",
    "    html = urllib.request.urlopen(url).read()\n",
    "    text = BeautifulSoup(html,\"html.parser\")\n",
    "    table = text.find(\"div\", class_ = \"t_list test20200330\")\n",
    "    tr = table.find_all(\"tr\")\n",
    "    for (i,j) in enumerate(tr):\n",
    "        if i > 0:\n",
    "            td = tr[i].find_all('td')\n",
    "            name = td[1].find(\"a\").text\n",
    "            date = td[4].text\n",
    "            url = \"http://ee.korea.ac.kr/ee/board/MajorBulletinBoard.do\" + td[1].find(\"a\")['href']\n",
    "            name_list.append(name)\n",
    "            date_list.append(date)\n",
    "            url_list.append(url)\n",
    "data = {\"날짜\" : date_list, \"전전 전공게시판\" : name_list,  \"url\" : url_list}\n",
    "df2 = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = []\n",
    "date_list = []\n",
    "url_list = []\n",
    "\n",
    "for num in range(0,page,10):\n",
    "    url = \"http://ee.korea.ac.kr/ee/board/FreeBulletinBoard.do?mode=list&&articleLimit=10&article.offset=\" + str(num)\n",
    "    html = urllib.request.urlopen(url).read()\n",
    "    text = BeautifulSoup(html,\"html.parser\")\n",
    "    table = text.find(\"div\", class_ = \"t_list test20200330\")\n",
    "    tr = table.find_all(\"tr\")\n",
    "    for (i,j) in enumerate(tr):\n",
    "        if i >0:\n",
    "            td = tr[i].find_all('td')\n",
    "            name = td[1].find(\"a\").text\n",
    "            date = td[4].text\n",
    "            url = \"http://ee.korea.ac.kr/ee/board/FreeBulletinBoard.do\" + td[1].find(\"a\")['href']\n",
    "            name_list.append(name)\n",
    "            date_list.append(date)\n",
    "            url_list.append(url)\n",
    "data = {\"날짜\" : date_list, \"전전 자유게시판\" : name_list,  \"url\" : url_list}\n",
    "df3 = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = []\n",
    "date_list = []\n",
    "url_list = []\n",
    "\n",
    "for num in range(0,page,10):\n",
    "    url = \"http://ee.korea.ac.kr/ee/board/JobBoard.do?mode=list&&articleLimit=10&article.offset=\" + str(num)\n",
    "    html = urllib.request.urlopen(url).read()\n",
    "    text = BeautifulSoup(html,\"html.parser\")\n",
    "    table = text.find(\"div\", class_ = \"t_list test20200330\")\n",
    "    tr = table.find_all(\"tr\")\n",
    "    for (i,j) in enumerate(tr):\n",
    "        if i > 0:\n",
    "            td = tr[i].find_all('td')\n",
    "            name = td[1].find(\"a\").text\n",
    "            date = td[4].text\n",
    "            url = \"http://ee.korea.ac.kr/ee/board/JobBoard.do\" + td[1].find(\"a\")['href']\n",
    "            name_list.append(name)\n",
    "            date_list.append(date)\n",
    "            url_list.append(url)\n",
    "data = {\"날짜\" : date_list, \"전전 취업게시판\" : name_list,  \"url\" : url_list}\n",
    "df4 = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df5,df6,df1,df2,df3,df4],axis=1)\n",
    "df[\" \"]= \" \"\n",
    "df.to_excel(title, engine = 'xlsxwriter')\n",
    "#os.system(\"open -a '/Applications/Microsoft Excel.app' '/Users/hyunwon/test2.xlsx'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wb = openpyxl.load_workbook(title)\n",
    "sheet1 = wb.active\n",
    "sheet1 = AutoFitColumnSize(sheet1,[1,2,4,5,7,8,10,11,13,14,16,17],0)\n",
    "wb.save(title)\n",
    "path = os.getcwd()\n",
    "full_path = path + \"/\" + title\n",
    "os.system(\"open -a '/Applications/Microsoft Excel.app' '%s'\" %full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
